<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content=""/>
  
  <title>Scrapy网络爬虫 | 淘淘的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="网络爬虫简单来说就是模拟用户操作浏览器或者app，并获取、筛选信息的程序。">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy网络爬虫">
<meta property="og:url" content="http://tonylit.me/2017/11/19/Scrapy网络爬虫/index.html">
<meta property="og:site_name" content="淘淘的博客">
<meta property="og:description" content="网络爬虫简单来说就是模拟用户操作浏览器或者app，并获取、筛选信息的程序。">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/爬虫.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/scrapy.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/pip-scrapy.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/startproject.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/projectdir.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/genspider.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/check.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/shell.PNG">
<meta property="og:image" content="http://tonylit.me/img/python爬虫/blog.PNG">
<meta property="og:updated_time" content="2017-11-19T05:37:27.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy网络爬虫">
<meta name="twitter:description" content="网络爬虫简单来说就是模拟用户操作浏览器或者app，并获取、筛选信息的程序。">
  
    <link rel="alternative" href="/atom.xml" title="淘淘的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/leaves.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <script src="http://libs.baidu.com/jquery/1.9.0/jquery.js"></script>
  <script src="http://tonylit.me//js/jquery.nicescroll.js"></script>

</head>

<body>

  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
<form class="search" method="get" accept-charset="utf-8">
			<input type="text" id="chillax-search-input" class="st-search-input_my" maxlength="30" placeholder="search" />
		</form>


	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/c.jpg" class="js-avatar">
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/" class="alluraregular">tonyli</a></h1>
		</hgroup>
        <!--
		
		<p class="header-subtitle">Nothing is given. Everything is earned.</p>
		
        -->
		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>

				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags/work">工作日志</a></li>
				        
							<li><a href="/tags/life">点滴生活</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/tonylit" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/2136920064/profile?topnav=1&wvr=6" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/li-tao-40-20-98" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>

				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Android/" style="font-size: 10px;">Android</a> <a href="/tags/Appium/" style="font-size: 12.86px;">Appium</a> <a href="/tags/Gatling/" style="font-size: 11.43px;">Gatling</a> <a href="/tags/Jmeter/" style="font-size: 11.43px;">Jmeter</a> <a href="/tags/Python/" style="font-size: 12.86px;">Python</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/atom/" style="font-size: 10px;">atom</a> <a href="/tags/docker/" style="font-size: 17.14px;">docker</a> <a href="/tags/java/" style="font-size: 18.57px;">java</a> <a href="/tags/kafka/" style="font-size: 10px;">kafka</a> <a href="/tags/life/" style="font-size: 10px;">life</a> <a href="/tags/loadrunner/" style="font-size: 14.29px;">loadrunner</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/pinpoint/" style="font-size: 11.43px;">pinpoint</a> <a href="/tags/scala/" style="font-size: 10px;">scala</a> <a href="/tags/springboot/" style="font-size: 11.43px;">springboot</a> <a href="/tags/work/" style="font-size: 15.71px;">work</a> <a href="/tags/性能/" style="font-size: 20px;">性能</a>
					</div>
				</section>
				

				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">Nothing is given. Everything is earned.</div>
				</section>
				
			</div>
		</div>
	</header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">tonyli</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/c.jpg" class="js-avatar">
				<hgroup>
				  <h1 class="header-author">tonyli</h1>
				</hgroup>
			</div>
			
			<p class="header-subtitle">Nothing is given. Everything is earned.</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags/work">工作日志</a></li>
		        
					<li><a href="/tags/life">点滴生活</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/tonylit" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/2136920064/profile?topnav=1&wvr=6" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/li-tao-40-20-98" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>
	</div>
</nav>

	  <div class="recent">
高手的存在，就是让服务10亿人的时候，你感觉只是为你一个人服务......
</div>

      <div class="body-wrap"><article id="post-Scrapy网络爬虫" class="article article-type-post" itemscope itemprop="blogPost">
    <script>
        $("html").niceScroll({
            cursorcolor: "#2a2929",
            cursoropacitymax: 1,
            touchbehavior: false,
            cursorwidth: "6px",
            cursorborder: "5",
            cursorborderradius: "0px",
            autohidemode: true
        });
    </script>
    
        <div class="article-meta">
            <a href="/2017/11/19/Scrapy网络爬虫/" class="article-date">
  	<time datetime="2017-11-19T03:37:27.000Z" itemprop="datePublished">2017-11-19</time>
</a>

        </div>
        
            <div class="article-inner">
                
                    <input type="hidden" class="isFancy" />
                    
                        
                            <header class="article-header">
                                
  
    <h1 class="article-title" itemprop="name">
      Scrapy网络爬虫
    </h1>
  


                            </header>
                            
                                <div class="article-info article-info-post">
                                    
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>
	</div>


                                        

                                            <div class="clearfix"></div>
                                </div>
                                
                                    
                                        <div class="article-entry" itemprop="articleBody">
                                            
                                                    <!--02-->
                                                    <div id="toc" class="toc-article">
    <div class="toc-title">目录</div>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy框架介绍"><span class="toc-number">1.</span> <span class="toc-text">Scrapy框架介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy框架图"><span class="toc-number">1.1.</span> <span class="toc-text">Scrapy框架图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#整体流程："><span class="toc-number">1.2.</span> <span class="toc-text">整体流程：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#制作Scrapy爬虫"><span class="toc-number">2.</span> <span class="toc-text">制作Scrapy爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#新建项目"><span class="toc-number">2.1.</span> <span class="toc-text">新建项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#创建Spider"><span class="toc-number">2.2.</span> <span class="toc-text">创建Spider</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scrapy_check"><span class="toc-number">2.2.1.</span> <span class="toc-text">scrapy check</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scrapy_crawl运行spider"><span class="toc-number">2.2.2.</span> <span class="toc-text">scrapy crawl运行spider</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pipelines-py"><span class="toc-number">2.2.3.</span> <span class="toc-text">pipelines.py</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy_shell"><span class="toc-number">2.3.</span> <span class="toc-text">scrapy shell</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实例：爬取博客文章信息"><span class="toc-number">3.</span> <span class="toc-text">实例：爬取博客文章信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#创建spider项目"><span class="toc-number">3.1.</span> <span class="toc-text">创建spider项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#创建spider爬虫"><span class="toc-number">3.2.</span> <span class="toc-text">创建spider爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#编写爬取逻辑"><span class="toc-number">3.3.</span> <span class="toc-text">编写爬取逻辑</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#编写items-py"><span class="toc-number">3.3.1.</span> <span class="toc-text">编写items.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写spider-py"><span class="toc-number">3.3.2.</span> <span class="toc-text">编写spider.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编写pipeline-py"><span class="toc-number">3.3.3.</span> <span class="toc-text">编写pipeline.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#修改settings-py"><span class="toc-number">3.3.4.</span> <span class="toc-text">修改settings.py</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy_check&&_scrapy_crawl"><span class="toc-number">3.4.</span> <span class="toc-text">scrapy check&& scrapy crawl</span></a></li></ol></li></ol>
</div>

                                                        
                                                            
                                                                
                                                                            <p>网络爬虫简单来说就是模拟用户操作浏览器或者app，并获取、筛选信息的程序。</p>
<p><img src="/img/python爬虫/爬虫.PNG" alt="Alt text"></p>
<a id="more"></a>
<hr>
<h1 id="Scrapy框架介绍">Scrapy框架介绍</h1><p>目前比较流行的python网络爬取框架-<a href="https://scrapy.org/" target="_blank" rel="external">Scrapy</a>,在数据挖掘、监测和自动化测试上也有一些应用。</p>
<h2 id="Scrapy框架图">Scrapy框架图</h2><p>Scrapy 使用 <a href="http://twistedmatrix.com/trac/" target="_blank" rel="external">Twisted</a>异步网络库来处理网络通讯，包含了各种中间件接口，可以灵活的完成各种需求。</p>
<p><img src="/img/python爬虫/scrapy.PNG" alt="Alt text"></p>
<p> Scrapy Engine（引擎）：总负责人。负责其他模块的通信、数据传递等。</p>
<p> Scheduler（调度器）：负责接收引擎发过来的request请求，放入队列中；当引擎需要时返回给引擎。</p>
<p>Downloader（下载器）: 负责下载引擎发送的所有request请求，将获取的reponse返回给引擎，引擎交给spiders模块进行数据处理。</p>
<p>Spiders（爬虫）：使用各种解析规则，分析提取Item数据，并将需要跟进的url提交给引擎，再次进入scheduler。</p>
<p>Item Pipeline（管道）：负责处理spider中获取的item，进行后续详细分析、存储等处理。</p>
<p>Downloader Middlewares和Spider Middlewares: 可以自定义扩展的组件。</p>
<h2 id="整体流程：">整体流程：</h2><blockquote>
<ol>
<li>引擎询问Spiders有木有需要爬取的url。</li>
<li>引擎获取到需要爬取的url，交给Scheduler，放入下载队列中。</li>
<li>引擎从Scheduler队列中拿到下一个需要爬取的url，交给Downloader进行下载。（如果下载失败了URL会再次进入Scheduler队列中）</li>
<li>引擎将Downloader下载的Response交给Spiders进行处理。</li>
<li>Spiders处理Response，把获取的item交给Item Pipeline；将需要继续跟进的url交给引擎放入Scheduler队列中。</li>
<li>循环1~5，直到Scheduler中不存在任何url。</li>
</ol>
</blockquote>
<hr>
<h1 id="制作Scrapy爬虫">制作Scrapy爬虫</h1><p>首先安装Scrapy，这里使用的python2.7版本</p>
<blockquote>
<p>pip install Scrapy </p>
</blockquote>
<p>输入scrapy，验证是否安装成功。<br><img src="/img/python爬虫/pip-scrapy.PNG" alt="Alt text"></p>
<h2 id="新建项目">新建项目</h2><p>执行 scrapy startproject project名字 即可。</p>
<p><img src="/img/python爬虫/startproject.PNG" alt="Alt text"></p>
<p><img src="/img/python爬虫/projectdir.PNG" alt="Alt text"></p>
<blockquote>
<p>scrapy.cfg : 项目的总体配置<br>items.py : 项目的目标文件<br>pipelines.py : 项目的管道文件<br>settings.py ：项目的配置文件<br>spiders文件夹：爬虫代码存储目录</p>
</blockquote>
<hr>
<h2 id="创建Spider">创建Spider</h2><p>进入spiders文件夹，执行scrapy genspider [-t template] <name> <domain> 命令即可</domain></name></p>
<p><img src="/img/python爬虫/genspider.PNG" alt="Alt text"></p>
<p>默认使用basic模板，执行后生成baiduspider.py文件：<br>修改parse方法，打印返回的body</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MicspiderSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'micspider'</span> <span class="comment">#保证唯一性</span></span><br><span class="line">    allowed_domains = [<span class="string">'www.mytest.com'</span>] </span><br><span class="line">    start_urls = [<span class="string">'http://www.mytest.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span> <span class="comment"># 负责解析返回的response，提取数据或者生成跟进的url对象</span></span><br><span class="line">       	<span class="keyword">print</span> response.body</span><br><span class="line">	<span class="comment"># pass</span></span><br></pre></td></tr></table></figure>
<h3 id="scrapy_check">scrapy check</h3><p>修改完spider文件，check一下。</p>
<blockquote>
<p>scrapy check micspider </p>
</blockquote>
<p>check后面的爬虫名称为spider文件中定义的name名称。</p>
<p><img src="/img/python爬虫/check.PNG" alt="Alt text"></p>
<h3 id="scrapy_crawl运行spider">scrapy crawl运行spider</h3><p>运行spider</p>
<blockquote>
<p>scrapy crawl micspider</p>
</blockquote>
<p>会打印出mic网站的body信息。</p>
<h3 id="pipelines-py">pipelines.py</h3><p>当item在spider中被收集后，它会被传递到item pipeline中，这些item pipeline组件按照settings.py文件中定义的顺序处理item。</p>
<p>我们修改一下生成的pipelines.py，把item打印到文件中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderprojectPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#可选实现，做一些初始化</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		self.f = open(<span class="string">"mic.json"</span>,<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#必须实现</span></span><br><span class="line">    <span class="comment">#item参数为spider返回的item数据</span></span><br><span class="line">    <span class="comment">#spider参数为获取item的spider对象</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        content = json.dumps(dict(item))</span><br><span class="line">		self.f.write(content)</span><br><span class="line">		<span class="keyword">return</span> item</span><br><span class="line">	</span><br><span class="line">	<span class="comment">#可选实现，放spider启动的时候，调用该方法</span></span><br><span class="line">	<span class="comment">#def open_spider(self,spider):</span></span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">#可选实现，当spider关闭时，调用该方法</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">		self.f.close()</span><br></pre></td></tr></table></figure></p>
<p>items.py 和 micspider.py 文件做相应修改：</p>
<p>items.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># http://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderprojectItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">     name = scrapy.Field()</span><br><span class="line">     </span><br><span class="line">     <span class="comment">#pass</span></span><br></pre></td></tr></table></figure>
<p>micspider.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">".."</span>)</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> items <span class="keyword">import</span> SpiderprojectItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MicspiderSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'micspider'</span></span><br><span class="line">    allowed_domains = [<span class="string">'www.mytest.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mytest.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">       </span><br><span class="line">	node = response.body</span><br><span class="line">	</span><br><span class="line">	item = SpiderprojectItem()</span><br><span class="line">	item[<span class="string">'name'</span>] = node</span><br><span class="line"></span><br><span class="line">	<span class="keyword">yield</span>  item</span><br></pre></td></tr></table></figure></p>
<p>修改settings.py文件，把pipeline的设置放开：</p>
<figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="component">ITEM_PIPELINES = &#123;</span><br><span class="line">    'spiderproject<span class="string">.pipelines.SpiderprojectPipeline':</span> 300,</span><br><span class="line">&#125;</span></span><br></pre></td></tr></table></figure>
<p>这里可以设置多个pipeline，300表示权重。<br>权重为1~1000之间，越小表示权重越大。</p>
<p>ok , 配置完以上信息，执行scrapy crawl micspider，<br>执行后会生成一个mic.json文件，里面是mic网站的body。</p>
<p>tips：<br>spider.py文件中，最后return的数据给引擎，由引擎来判断由谁处理数据。<br>当return的数据为item类型时，引擎才交给pipeline处理。</p>
<hr>
<h2 id="scrapy_shell">scrapy shell</h2><p>执行scrapy shell xxxx，启动一个交互终端，方便进行爬取的网页数据调试，比如测试xpath。</p>
<blockquote>
<p>scrapy shell <a href="http://tonylit.me/">http://tonylit.me/</a></p>
</blockquote>
<p><img src="/img/python爬虫/shell.PNG" alt="Alt text"></p>
<hr>
<p>以上就是scrapy爬虫主要的功能点。</p>
<hr>
<h1 id="实例：爬取博客文章信息">实例：爬取博客文章信息</h1><p>下面对我自己的博客进行文章标题、标签、链接、发布时间进行爬取。实现一个简单的scrapy爬虫。</p>
<p>url: <a href="http://tonylit.me/">http://tonylit.me/</a></p>
<p><img src="/img/python爬虫/blog.PNG" alt="Alt text"></p>
<hr>
<h2 id="创建spider项目">创建spider项目</h2><p>项目的名字：myblogspider</p>
<blockquote>
<p>scrapy startproject myblogspider</p>
</blockquote>
<hr>
<h2 id="创建spider爬虫">创建spider爬虫</h2><p>爬虫的名字：tonylitspider </p>
<p>进入myblogspider文件夹中，执行：</p>
<blockquote>
<p>scrapy genspider tonylitspider ‘tonylit.me’</p>
</blockquote>
<p>在spiders文件夹中生成tonylitspider.py的爬虫文件</p>
<hr>
<h2 id="编写爬取逻辑">编写爬取逻辑</h2><p>在编写之前，先把需要爬取信息的xpath弄清楚。</p>
<blockquote>
<p>title-list: //a[@class=’article-title’]/text()<br>tag-list:  //ul[@class=’article-tag-list’]/li/a/text()<br>link-list：//a[@class=’article-title’]/@href<br>time-list ：//time/@datetime</p>
</blockquote>
<h3 id="编写items-py">编写items.py</h3><p>定义四个变量，存储文章的标题、标签、链接、发布时间。</p>
<figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor"># -*- coding: utf-8 -*-</span><span class="preprocessor"></span><br><span class="line"></span><br><span class="line"># Define here the models for your scraped items</span><span class="preprocessor"></span><br><span class="line">#</span><span class="preprocessor"></span><br><span class="line"># See documentation in:</span><span class="preprocessor"></span><br><span class="line"># http://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="preprocessor"><span class="keyword">import</span> scrapy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyblogspiderItem</span>(<span class="title">scrapy</span>.<span class="title">Item</span>):</span><span class="preprocessor"></span><br><span class="line">    # define the fields for your item here like:</span><span class="preprocessor"></span><br><span class="line">    # 文章标题</span></span><br><span class="line">    title = scrapy.<span class="keyword">Field</span>()<span class="preprocessor"></span><br><span class="line">    # 文章标签</span></span><br><span class="line">    tag = scrapy.<span class="keyword">Field</span>()<span class="preprocessor"></span><br><span class="line">    # 文章链接</span></span><br><span class="line">    link = scrapy.<span class="keyword">Field</span>()<span class="preprocessor"></span><br><span class="line">    # 发布时间</span></span><br><span class="line">    time = scrapy.<span class="keyword">Field</span>()</span><br></pre></td></tr></table></figure>
<h3 id="编写spider-py">编写spider.py</h3><p>编写上面生成的tonylitspider.py，实现信息的爬取。</p>
<p>找到下一页的xpath：</p>
<blockquote>
<p>下一页：//a[@class=’extend next’]/@href</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">".."</span>)</span><br><span class="line"><span class="keyword">from</span> items <span class="keyword">import</span> MyblogspiderItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TonylitspiderSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#爬虫名称</span></span><br><span class="line">    name = <span class="string">'tonylitspider'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#爬取域范围，允许爬虫在这个域名下进行爬取（可选）</span></span><br><span class="line">    allowed_domains = [<span class="string">'tonylit.me'</span>]</span><br><span class="line">    </span><br><span class="line">    baseURL = <span class="string">"http://tonylit.me/"</span></span><br><span class="line">    <span class="comment">#从此url开始爬取</span></span><br><span class="line">    start_urls = [<span class="string">'http://tonylit.me/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">	</span><br><span class="line">        <span class="comment">#获取文章标题</span></span><br><span class="line">	title_list = response.xpath(<span class="string">"//a[@class='article-title']/text()"</span>).extract()</span><br><span class="line">	</span><br><span class="line">        <span class="comment">#获取文章标签</span></span><br><span class="line">        tag_list = response.xpath(<span class="string">"//ul[@class='article-tag-list']/li/a/text()"</span>).extract()</span><br><span class="line"></span><br><span class="line">	<span class="comment">#获取文章链接</span></span><br><span class="line">        link_list = response.xpath(<span class="string">"//a[@class='article-title']/@href"</span>).extract()</span><br><span class="line"></span><br><span class="line">	<span class="comment">#获取发布时间</span></span><br><span class="line">        time_list =  response.xpath(<span class="string">"//time/@datetime"</span>).extract()</span><br><span class="line"></span><br><span class="line">	<span class="comment">#创建items对象-orm</span></span><br><span class="line">	items = MyblogspiderItem()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment">#每页8篇文章</span></span><br><span class="line">		<span class="keyword">for</span> temp <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">8</span>):</span><br><span class="line">	        	<span class="comment">#存储文章标题到item	</span></span><br><span class="line">        		items[<span class="string">'title'</span>] = title_list[temp].encode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">        		<span class="comment">#存储文章标签到item </span></span><br><span class="line">			items[<span class="string">'tag'</span>] = tag_list[temp].encode(<span class="string">"utf-8"</span>)</span><br><span class="line">	</span><br><span class="line">        		<span class="comment">#存储文章链接到item </span></span><br><span class="line">			items[<span class="string">'link'</span>] = str(<span class="string">"http://tonylit.me"</span>) + link_list[temp].encode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">        		<span class="comment">#存储发布时间到item </span></span><br><span class="line">			items[<span class="string">'time'</span>] = time_list[temp].encode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">			<span class="keyword">yield</span> items</span><br><span class="line"></span><br><span class="line">	<span class="keyword">except</span> :</span><br><span class="line">		<span class="keyword">print</span> <span class="string">"error"</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="comment">#进行翻页处理</span></span><br><span class="line">		nextPage = response.xpath(<span class="string">"//a[@class='extend next']/@href"</span>).extract()[<span class="number">0</span>].encode(<span class="string">"utf-8"</span>)</span><br><span class="line">		<span class="keyword">if</span>  len(nextPage) != <span class="number">0</span>:</span><br><span class="line">			nextURL = <span class="string">'http://tonylit.me/'</span>+ str(nextPage) </span><br><span class="line">			<span class="keyword">print</span> nextURL	</span><br><span class="line">			<span class="comment">#递归调用parse</span></span><br><span class="line">			<span class="keyword">yield</span> scrapy.Request(nextURL,callback = self.parse)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span> : </span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h3 id="编写pipeline-py">编写pipeline.py</h3><p>编写管道文件，把爬取的信息输出到文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyblogspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#初始化，打开tonylit.json文件，用来写入items</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">	self.f = open(<span class="string">"tonylit.json"</span>,<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        </span><br><span class="line">	<span class="comment">#把item转成字典，写入文件中</span></span><br><span class="line">     	content = json.dumps(dict(item)) + <span class="string">", \n"</span></span><br><span class="line">        self.f.write(content)</span><br><span class="line">        </span><br><span class="line"> 	<span class="keyword">return</span> item</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#spider全部结束后，关闭文件</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">	self.f.close()</span><br></pre></td></tr></table></figure>
<h3 id="修改settings-py">修改settings.py</h3><p>把ITEM_PIPELINES 配置放开，启用pipeline</p>
<figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="component">ITEM_PIPELINES = &#123;</span><br><span class="line">    'myblogspider<span class="string">.pipelines.MyblogspiderPipeline':</span> 300,</span><br><span class="line">&#125;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="scrapy_check&amp;&amp;_scrapy_crawl">scrapy check&amp;&amp; scrapy crawl</h2><p>编写完成后，先进行check，再执行爬虫</p>
<blockquote>
<p>scrapy check tonylitspider<br>scrapy crawl tonylitspider</p>
</blockquote>
<p>执行后，生成tonylit.json，里面就是爬取的信息了。</p>

                                                                                
                                        </div>
                                        
            </div>
            
                <div class="bdsharebuttonbox" style="margin-top:10px;margin-left:30px;float:left;">
                    <a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a>
                    <a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a>
                    <a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a>
                    <a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a>
                    <a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a>
                    <a href="#" class="bds_more" data-cmd="more"></a>
                </div>
                <script>
                    window._bd_share_config = {
                        "common": {
                            "bdSnsKey": {},
                            "bdText": "",
                            "bdMini": "1",
                            "bdMiniList": false,
                            "bdStyle": "2",
                            "bdSize": "16"
                        },
                        "share": {}
                    };
                    with(document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];
                </script>
                
                    
                        
<nav id="article-nav">
  
    <a href="/2017/12/09/Android开发环境安装/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Android开发环境安装
        
      </div>
    </a>
  
  
    <a href="/2017/11/03/自制python包并安装到系统中/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">自制python包并安装到系统中</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>


                            
                                <!-- 多说评论框 start -->
                                
                                    <div class="ds-thread" data-thread-key="post-Scrapy网络爬虫" data-title="Scrapy网络爬虫" data-url="http://tonylit.me/2017/11/19/Scrapy网络爬虫/"></div>
                                    <!-- 多说评论框 end -->
                                    <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
                                    <script type="text/javascript">
                                        var duoshuoQuery = {
                                            short_name: "tonylit"
                                        };
                                        (function() {
                                            var ds = document.createElement('script');
                                            ds.type = 'text/javascript';
                                            ds.async = true;
                                            ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
                                            ds.charset = 'UTF-8';
                                            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
                                        })();
                                    </script>
                                    <!-- 多说公共JS代码 end -->
                                    
</article>

<!--

    <div style="width:100%;background-color:#fff;">
        <div id="uyan_frame" style="margin:auto 10px 10px 10px;"></div>
    </div>
    <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2017540"></script>
    
-->
<!--

-->

</div>
      <!--<footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2019 tonyli
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
    
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','ZDWgkzoEyRjqY6u-8gjX','2.0.0');
</script>
   
  </div>
</footer>-->
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/mobile.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>
<script src="/js/prefixfree.js" type="text/javascript"></script>
<script src="/js/require-2.1.20.js" type="text/javascript"></script>
<script src="/js/jquery-1.9.1.min.js" type="text/javascript"></script>




<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div id="totop" style="position:fixed;bottom:150px;right:50px;cursor: pointer;z-index:9999;opacity: 100%;">
    <a title="返回顶部" style="opacity: 100%;">
        <img src="/img/scrollup.png" />
    </a>
</div>

<script src="/js/totop.js"></script>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','ZDWgkzoEyRjqY6u-8gjX','2.0.0');
</script>

  </div>
</body>
</html>
